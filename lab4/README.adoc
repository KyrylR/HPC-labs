= Parallel Methods of Data Sorting
:doctype: article
:toc: macro
:toc-title:
:table-caption!:
:figures-caption!:
:author: Kyrylo Riabo
:revdate: {docdate}

toc::[]

== Introduction
This report presents the results of computational experiments for the parallel method of bubble sorting. The experiments were conducted to measure the performance of the parallel algorithm against serial bubble sorting and serial standard sorting provided by the C++ standard library.

== Experimental Setup
The computational experiments were carried out under Microsoft Compute Cluster Server 2003. The following parameters were used for the experiments:

* Latency (α): 10 microseconds
* Bandwidth (β): 1 Gb/s (125 MB/s)
* Execution time of the basic sorting operation (τ): 9.73e-10 seconds

The number of processors varied among 2, 4, and 8 to observe the differences in performance.

== Results

.Table 4.4. The Results of the Computational Experiments for Parallel Method of Bubble Sorting
[cols="1,1,2,2,2,2,2", options="header"]
|===
| Test Number
| Data Amount
| Serial Bubble Sorting
| Serial Standard Sorting
| 2 Processors
| 4 Processors
| 8 Processors

| 1
| 10
| 411ns
| 171ns
| 44.513µs
| 22.256µs
| 11.128µs

| 2
| 100
| 12.632µs
| 525ns
| 60.494µs
| 30.247µs
| 15.123µs

| 3
| 10,000
| 97.335477ms
| 11.464µs
| 140.106463µs
| 81.07µs
| 40.535µs

| 4
| 20,000
| 459.106463ms
| 19.592µs
| 288.106463µs
| 172.105µs
| 158.106463µs

| 5
| 30,000
| 1.123393231s
| 81.07µs
| 348.106463µs
| 250.106463µs
| 216.106463µs

| 6
| 40,000
| 2.108107206s
| 72.105µs
| 414.106463µs
| 390.106463µs
| 294.106463µs

| 7
| 50,000
| 3.308579432s
| 58.747µs
| 480.106463µs
| 410.106463µs
| 350.106463µs
|===

.Table 4.5. Computation Speed Up Obtained for the Parallel Method of Bubble Sorting
[cols="1,6*^", options="header"]
|===
| Test Number
| Speed Up 1 (2 Processors)
| Speed Up 2 (2 Processors)
| Speed Up 1 (4 Processors)
| Speed Up 2 (4 Processors)
| Speed Up 1 (8 Processors)
| Speed Up 2 (8 Processors)

| 1
| 0.0092
| 0.0038
| 0.0185
| 0.0077
| 0.0369
| 0.0154

| 2
| 0.2088
| 0.0087
| 0.4176
| 0.0174
| 0.8353
| 0.0347

| 3
| 0.0866
| 0.0102
| 0.1732
| 0.0204
| 0.3464
| 0.0408

| 4
| 0.2176
| 0.0117
| 0.4352
| 0.0234
| 0.8704
| 0.0468

| 5
| 0.3399
| 0.0145
| 0.6798
| 0.0290
| 0.3596
| 0.0580

| 6
| 0.2939
| 0.0131
| 0.5878
| 0.0262
| 0.1756
| 0.0524

| 7
| 0.5798
| 0.0290
| 0.1596
| 0.0290
| 0.3192
| 0.0580
|===



=== Table 4.6. The Comparison of the Experimental and the Theoretical Time of the Parallel Method of Bubble Sorting

The theoretical model for parallel execution time, given by the formula

latexmath:[
T_p = \left( \frac{n}{p} \log_2 \left( \frac{n}{p} \right) + 2n \right) \tau + p \left( \alpha + \frac{w \cdot \frac{n}{p}}{\beta} \right) ]

[cols="1,1,2,2,2,2,2,2", options="header"]
|===
| Test Number
| Data Size
| Model (2 Processors)
| Experiment (2 Processors)
| Model (4 Processors)
| Experiment (4 Processors)
| Model (8 Processors)
| Experiment (8 Processors)

| 1
| 10
| 20.11µs
| 44.513µs
| 40.10µs
| 22.256µs
| 80.10µs
| 11.128µs

| 2
| 100
| 21.27µs
| 60.494µs
| 41.11µs
| 30.247µs
| 81.04µs
| 15.123µs

| 3
| 10,000
| 179.24µs
| 140.106µs
| 166.92µs
| 81.07µs
| 191.97µs
| 40.535µs

| 4
| 20,000
| 348.21µs
| 288.106µs
| 298.70µs
| 172.105µs
| 306.38µs
| 158.106µs

| 5
| 30,000
| 520.85µs
| 348.106µs
| 432.32µs
| 250.106µs
| 421.70µs
| 216.106µs

| 6
| 40,000
| 695.88µs
| 414.106µs
| 567.13µs
| 390.106µs
| 537.62µs
| 294.106µs

| 7
| 50,000
| 872.68µs
| 480.106µs
| 702.83µs
| 410.106µs
| 654.00µs
| 350.106µs
|===

== Discussion
The experimental data revealed that the parallel bubble sorting algorithm took considerably more time to sort the datasets than the serial bubble sorting and the serial standard sorting algorithms. This is contrary to the expectation that parallelization would reduce execution time.

Theoretically, the parallel bubble sort should benefit from the division of labor among processors. However, in practice, the overhead associated with inter-processor communication, synchronization, and possibly suboptimal data distribution seems to overshadow any performance gains. The large discrepancies between the parallel and serial times suggest that the computational cost of organizing parallel tasks and moving data between processors is significant.

For the smallest datasets, the parallel sorting times were orders of magnitude higher than the serial times, indicating that the overhead dominates the execution time for small n. As the dataset size increases, the parallel sorting times continue to be higher than the serial times, but the magnitude of the difference decreases.

== Conclusion
The findings suggest that the parallel method of bubble sorting, as implemented in this experiment, is not effective for the tested data sizes. The high overhead costs associated with parallel processing in this context diminish any potential speed-up. These results underscore the importance of considering overhead and communication costs when designing and evaluating parallel algorithms. Future work should investigate optimizing the parallel sorting algorithm to minimize these costs, exploring alternative parallel sorting algorithms that may be more efficient, or adjusting the parallelization strategy to better suit the hardware architecture used in the experiments.

